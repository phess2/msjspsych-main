{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import itertools \n",
    "from pathlib import Path\n",
    "np.random.seed(0)\n",
    "# 0, -3, -6, -12\n",
    "# azims = 0, 10, 30\n",
    "# elevs = 0, 20, 40\n",
    "# target = (0, -20), (0, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_sounds = Path('/Users/mcdermottspeakerarray/Documents/binaural_cocktail_party/msjspsych-main/experiment_spatial_word_recognition_thresholds/threshold_sounds/sounds')\n",
    "target_wav_list= list((path_to_sounds / 'target_excerpts').glob(\"*.wav\"))\n",
    "target_dir = (path_to_sounds / 'target_excerpts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manifest = pd.read_pickle('/Users/mcdermottspeakerarray/Documents/binaural_cocktail_party/msjspsych-main/experiment_spatial_word_recognition_thresholds/full_cue_target_distractor_df_w_meta.pdpkl')\n",
    "manifest = manifest[~manifest.client_id.str.contains('bowie|1906-cc|laurahale')] # cull examples that made it through screening \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get trials locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_to_label(loc):\n",
    "    azim, elev = loc\n",
    "    elev_string_map = {40:'A', 30:'B', 20:'C', 10:'D', 0:'E', -10:'F', -20:'G'}\n",
    "    return elev_string_map[elev] + str(int((azim + 100) / 10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gen speaker label map: \n",
    "azim_elev_pairs = [(azim, elev) for azim, elev in itertools.product(*[np.arange(-90,91,10), np.arange(-20,41,10)])]\n",
    "label_to_loc_dict = {loc_to_label(loc):loc for loc in azim_elev_pairs}\n",
    "loc_to_label_dict = {loc:label for label,loc in label_to_loc_dict.items()}\n",
    "\n",
    "## save out \n",
    "out_dir = Path('./')\n",
    "\n",
    "##  just run once \n",
    "\n",
    "\n",
    "# with open(out_dir / f'array_label_to_loc_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(label_to_loc_dict, f)\n",
    "\n",
    "# with open(out_dir / f'array_loc_to_label_dict.pkl', 'wb') as f:\n",
    "#     pickle.dump(loc_to_label_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_elev</th>\n",
       "      <th>delta</th>\n",
       "      <th>dist_elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-20</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>40</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target_elev  delta  dist_elev\n",
       "0           -20   10.0         10\n",
       "1           -20   30.0         10\n",
       "2           -20   60.0         10\n",
       "3           -10   10.0         10\n",
       "4           -10   30.0         10\n",
       "5             0   10.0         10\n",
       "6             0   30.0         10\n",
       "7            10   10.0         10\n",
       "8            10   30.0         10\n",
       "9            20   10.0         10\n",
       "10           20   30.0         10\n",
       "11           30   10.0         10\n",
       "12           30   30.0         10\n",
       "13           40   10.0         10\n",
       "14           40   30.0         10\n",
       "15           40   60.0         10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNR=0\n",
    "n_per_condition=10\n",
    "\n",
    "## \n",
    "target_elevs = np.arange(-20,41,10)\n",
    "distractor_deltas = [None, 10, 30, 60]\n",
    "target_dist_delta_pairs = list(itertools.product(*[target_elevs, distractor_deltas]) )\n",
    "\n",
    "\n",
    "# get distractor positions\n",
    "\n",
    "trials = []\n",
    "for target_elev, dist_delta in target_dist_delta_pairs:\n",
    "        # print(dist_delta)\n",
    "    for n in range(n_per_condition):\n",
    "        if dist_delta:\n",
    "            if target_elev == -20:\n",
    "                dist_azim = dist_delta + target_elev\n",
    "            elif target_elev == 40:\n",
    "                dist_azim = target_elev - dist_delta \n",
    "            else:\n",
    "                direction = 1 if n % 2 else -1 \n",
    "                # print('\\t',  (dist_delta * direction))\n",
    "                dist_azim = target_elev + (dist_delta * direction)\n",
    "                if dist_azim < -20:\n",
    "                    dist_azim = target_elev + dist_delta \n",
    "                elif dist_azim > 40:\n",
    "                    dist_azim = target_elev - dist_delta \n",
    "            if dist_azim < -20 or dist_azim > 40:\n",
    "                continue\n",
    "            trials.append((target_elev, dist_azim, abs(dist_delta)))\n",
    "        else:\n",
    "            trials.append((target_elev, None, None))\n",
    "            \n",
    "# trials = np.array(trials)\n",
    "# print(np.unique(trials[:,2], return_counts=True))\n",
    "# np.unique(trials, return_counts=True, axis=0)\n",
    "df = pd.DataFrame.from_records(trials, columns=['target_elev', 'dist_elev', 'delta'])\n",
    "df.groupby(['target_elev','delta']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_df(df, group, cond1, cond2, n):\n",
    "    df_1 = df[df[f'{group}'] == cond1]\n",
    "    df_2 = df[df[f'{group}'] == cond2]\n",
    "    df_1_sample = df_1.sample(n=n)\n",
    "    df_2_sample = df_2[~df_2.word.isin(df_1_sample.word)].sample(n=n, replace=True)\n",
    "    # keep original ixs to track metadata in analysis scripts \n",
    "    df_1_sample = df_1_sample.reset_index()\n",
    "    df_1_sample.rename(columns={'index':'full_df_index'}, inplace=True)\n",
    "    df_2_sample = df_2_sample.reset_index()\n",
    "    df_2_sample.rename(columns={'index':'full_df_index'}, inplace=True)\n",
    "    return pd.concat([df_1_sample, df_2_sample], axis=0, ignore_index=True)\n",
    "\n",
    "def get_subset_df(df, n_words=480):\n",
    "    n_to_samp = n_words // 4\n",
    "    female_df = sample_df(df[df.gender == 'female'], 'sex_cond', 'same', 'different',n_to_samp)\n",
    "    male_df = sample_df(df[(df.gender == 'male') & (~df.word.isin(female_df.word))], 'sex_cond', 'same', 'different', n_to_samp)\n",
    "    return pd.concat([female_df, male_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10 \n",
    "\n",
    "n + (n % 4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target key list \n",
    "\n",
    "SNR = 0 \n",
    "def create_new_experiment(num_elev_trials=1,\n",
    "                          num_azim_trials=1):\n",
    "    target_elevs = np.arange(-20,41,10)\n",
    "    distractor_deltas = [None, 10, 30, 60]\n",
    "    target_dist_elev_delta_pairs = list(itertools.product(*[target_elevs, distractor_deltas]))\n",
    "\n",
    "    elev_trials = []\n",
    "    for target_elev, dist_delta in target_dist_elev_delta_pairs:\n",
    "            # print(dist_delta)\n",
    "        for n in range(num_elev_trials):\n",
    "            if dist_delta:\n",
    "                if target_elev == -20:\n",
    "                    dist_elev = dist_delta + target_elev\n",
    "                elif target_elev == 40:\n",
    "                    dist_elev = target_elev - dist_delta \n",
    "                else:\n",
    "                    direction = 1 if n % 2 else -1 \n",
    "                    # print('\\t',  (dist_delta * direction))\n",
    "                    dist_elev = target_elev + (dist_delta * direction)\n",
    "                    if dist_elev < -20:\n",
    "                        dist_elev = target_elev + dist_delta \n",
    "                    elif dist_elev > 40:\n",
    "                        dist_elev = target_elev - dist_delta \n",
    "                if dist_elev < -20 or dist_elev > 40:\n",
    "                    continue\n",
    "                elev_trials.append(([(0, 0), (0,target_elev)], (0,dist_elev), 0, dist_delta, SNR))\n",
    "            else:\n",
    "                elev_trials.append(([(0, 0), (0,target_elev)], None, 0, None, SNR))\n",
    "\n",
    "    ## Azimuth trials for main experiment:\n",
    "    target_azims = np.arange(-90,91,10)\n",
    "    target_dist_azim_delta_pairs = list(itertools.product(*[target_azims, distractor_deltas]) )\n",
    "\n",
    "    azim_trials = []\n",
    "    for target_azim, dist_delta in target_dist_azim_delta_pairs:\n",
    "            # print(dist_delta)\n",
    "        for n in range(num_azim_trials):\n",
    "            if dist_delta:\n",
    "                if target_azim == -90:\n",
    "                    dist_azim = dist_delta + target_azim\n",
    "                elif target_elev == 90:\n",
    "                    dist_azim = target_azim - dist_delta \n",
    "                else:\n",
    "                    direction = 1 if n % 2 else -1 \n",
    "                    # print('\\t',  (dist_delta * direction))\n",
    "                    dist_azim = target_azim + (dist_delta * direction)\n",
    "                    if dist_azim < -90:\n",
    "                        dist_azim = target_azim + dist_delta \n",
    "                    elif dist_azim > 90:\n",
    "                        dist_azim = target_azim - dist_delta \n",
    "                if dist_azim < -90 or dist_azim > 90:\n",
    "                    continue\n",
    "                # structure is cue loc, target loc, dist loc, azim delta, elev delta, SNR \n",
    "                azim_trials.append(([(0, 0), (target_azim, 0)], (dist_azim, 0), dist_delta, 0, SNR))\n",
    "            else:\n",
    "                # structure is cue loc, target loc, dist loc, azim delta, elev delta, SNR \n",
    "                azim_trials.append(([(0, 0), (target_azim,0 )], None, 0, None, SNR))\n",
    "            \n",
    "    all_trials = elev_trials + azim_trials \n",
    "\n",
    "    np.random.shuffle(all_trials)\n",
    "\n",
    "    n_total_trials = len(all_trials)\n",
    "    print(f\"Generating {n_total_trials} trials\")\n",
    "\n",
    "    path_to_sounds = Path('/Users/mcdermottspeakerarray/Documents/binaural_cocktail_party/msjspsych-main/experiment_spatial_word_recognition_thresholds/threshold_sounds/sounds')\n",
    "    target_dir = list((path_to_sounds / 'target_excerpts').glob(\"*.wav\"))\n",
    "    distractor_dir = list((path_to_sounds / 'distractor_excerpts').glob(\"*.wav\"))\n",
    "    cue_dir = list((path_to_sounds / 'cue_excerpts').glob(\"*.wav\"))\n",
    "\n",
    "    full_df = pd.read_pickle('/Users/mcdermottspeakerarray/Documents/binaural_cocktail_party/msjspsych-main/experiment_spatial_word_recognition_thresholds/full_cue_target_distractor_df_w_meta.pdpkl')\n",
    "    full_df = full_df[~full_df.client_id.str.contains('bowie|1906-cc|laurahale')] # cull examples that made it through screening \n",
    "    if n_total_trials % 4 != 0:\n",
    "        n_to_draw = n_total_trials + (n_total_trials % 4) ## need to draw n samples divisible by 4\n",
    "    else:\n",
    "        n_to_draw = n_total_trials\n",
    "        \n",
    "    participant_trial_stim_df = get_subset_df(full_df, n_words=n_to_draw).sample(frac=1.0)\n",
    "    ## just need trial indices to get audio. Will match full_df_index string to ix number from participant_trial_df\n",
    "    participant_stim_ixs = participant_trial_stim_df.full_df_index.to_list() \n",
    "    i = 0\n",
    "    array_manifest = []\n",
    "    for j, trial in enumerate(all_trials):\n",
    "        trial_idx = participant_stim_ixs[i]\n",
    "        i += 1\n",
    "        ix_pattern = f\"full_df_ix_{trial_idx:04}\"\n",
    "        ## Match ix pattern to file paths in cue, target, and distractor directories \n",
    "        cue_src_fn = [path for path in cue_dir if ix_pattern in path.stem]\n",
    "        target_src_fn = [path for path in target_dir if ix_pattern in path.stem]\n",
    "        # will get to distractors - only keep one for elevation trials \n",
    "        distractor_src_fn = [path for path in distractor_dir if ix_pattern in path.stem]\n",
    "        if trial[1] is None:\n",
    "            distractor_src_fn = None\n",
    "        array_manifest.append((trial[0], trial[1], trial[4], cue_src_fn, target_src_fn, distractor_src_fn))\n",
    "\n",
    "    experiment_data = dict()\n",
    "\n",
    "    for j, trial in enumerate(all_trials):\n",
    "        # dist_loc\n",
    "        experiment_data[f'trial_{j}'] = {'target_loc': trial[0][1],\n",
    "                                    'distractor_loc': trial[1],\n",
    "                                    'azim_delta': trial[2],\n",
    "                                    'elev_delta': trial[3],\n",
    "                                    'snr': trial[4],\n",
    "                                    'target_speaker_label':loc_to_label(trial[0][1]),\n",
    "                                    'distractor_speaker_label':loc_to_label(trial[1]) if trial[1] else None,\n",
    "                                    }\n",
    "        \n",
    "    trial_dict = {i:vals for i,vals in enumerate(array_manifest)}\n",
    "    return experiment_data, array_manifest, trial_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 534 trials\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "experiment_data, array_manifest, trial_dict = create_new_experiment(10,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make manifest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 534 trials\n",
      "534 total trials\n",
      "participant_004\n"
     ]
    }
   ],
   "source": [
    "# write out manifests \n",
    "import pickle \n",
    "from pathlib import Path\n",
    "# get n files in output dir \n",
    "\n",
    "# Name of sub directory to save experiment results - should match dir of trial dicts!\n",
    "EXP_TYPE = \"localize_speech_in_elevation_w_distractor_v00\" \n",
    "\n",
    "out_dir = Path(f'speaker_array_manifests/{EXP_TYPE}')\n",
    "exp_key_dir = Path(f'experiment_keys/{EXP_TYPE}')\n",
    "out_dir.mkdir(exist_ok=True, parents=True)\n",
    "exp_key_dir.mkdir(exist_ok=True, parents=True)\n",
    "n_files = len(list(out_dir.glob('*manifest.pkl')))\n",
    "\n",
    "np.random.seed(n_files+1) # change seed for each participant!!!! \n",
    "\n",
    "N_PER_ELEV = 10\n",
    "N_PER_AZIM = 4\n",
    "experiment, array_manifest, trial_dict = create_new_experiment(num_elev_trials=N_PER_ELEV,\n",
    "                                                               num_azim_trials=N_PER_AZIM\n",
    "                                                              )\n",
    "\n",
    "print(f\"{len(trial_dict)} total trials\")\n",
    "\n",
    "PART_NAME = f\"participant_{n_files+1:03d}\"\n",
    "print(PART_NAME)\n",
    "\n",
    "# meta will include speaker label \n",
    "with open(out_dir / f'{PART_NAME}_pilot_meta.pkl', 'wb') as f:\n",
    "    pickle.dump(experiment, f)\n",
    "\n",
    "with open(out_dir / f'{PART_NAME}_pilot_array_manifest.pkl', 'wb') as f:\n",
    "    pickle.dump(array_manifest, f)\n",
    "\n",
    "with open(out_dir / f'{PART_NAME}_pilot_trial_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(trial_dict, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
